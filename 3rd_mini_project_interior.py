# -*- coding: utf-8 -*-
"""3rd_mini_project_interior.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16IQ6gAkayg_z9WubpZ38KBGZqTQHegsf

# 데이터 불러오기
"""

import torch 
import random

import torchvision
from torchvision import datasets 
from torchvision import transforms

import glob
import os
import pandas as pd
import matplotlib.image as mpimg
import matplotlib.font_manager
import matplotlib.pyplot as plt
import numpy as np
import cv2

from PIL import Image

from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn as nn 
import torch.optim as optim 
import torch.nn.functional as F
from tqdm import tqdm 

import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.utils.tensorboard import SummaryWriter
from copy import deepcopy

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# !sudo apt-get install -y fonts-nanum
# !sudo fc-cache -fv
# !rm ~/.cache/matplotlib -rf

# import matplotlib.pyplot as plt
# plt.rc('font', family='NanumBarunGothic')

from google.colab import drive
drive.mount('/content/drive')
!cp '/content/drive/MyDrive/Project/open.zip' './'
!unzip -q open.zip -d remodel/ # remodel이라는 디렉토리 생성성

data_dir = './remodel/'

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

"""# 데이터 전처리 시작"""

# origin = df

filepath = glob.glob('./remodel/train/*/*.png')

df = pd.DataFrame(columns=['image','label'])
df['image'] = filepath
df['label']=df['image'].str.split('/').str[-2]

df['label'].nunique()

encoding = LabelEncoder()
df['label_encoding'] = encoding.fit_transform(df['label'])
df['label_encoding'].nunique()
# encoding.inverse_transform (encoding 한 코드 다시 원본으로 )

train_set, valid_set , _,_ = train_test_split(df,df['label_encoding'],test_size=0.2, stratify=df['label_encoding'],random_state=42)
# stratify : class 비율을 일정하게 만들어 준다. Target 값으로 넣어주면 그 값의 비율에 맞게 나누어 주기 때문에 꼭 필요!

"""#나만의 데이터셋 만들기"""

transform = A.Compose([A.Resize(224, 224),  A.Normalize(), A.RandomRotate90(), ToTensorV2()])

class MyData(Dataset):
    def __init__(self, image_filepath, label_filepath, transform=None):
        self.image_filepath = image_filepath
        self.label_filepath = label_filepath
        self.transform = transform

    def __len__(self):
        return len(self.image_filepath)

    def __getitem__(self,index):

        image = self.image_filepath[index]
        image = Image.open(image) # .convert('RGB')
        image = np.asarray(image)
        # image = cv2.imread(image)
        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        if self.transform is not None:
            image = self.transform(image=image)['image']

        if self.label_filepath is not None:
            label = self.label_filepath[index]
            return image, label
        else:
            return image

trainset = MyData(train_set['image'].values, train_set['label_encoding'].values,transform=transform)
validset = MyData(valid_set['image'].values, valid_set['label_encoding'].values,transform=transform)

print(type(trainset), len(trainset))
print(type(validset), len(validset))

imageset = MyData(train_set['image'].values, train_set['label_encoding'].values, transform=transform)

imageset[0][1]

def visual(count=4, orig_image=None, label=None, augmentor=None):
    image_list = ['image']
    label_list = ['Original']
    mean=(0.485, 0.456, 0.406)
    std=(0.229, 0.224, 0.225)

    for i in range(count):
        # transfrom
        # (image - mean) / std
        augmented_image = augmentor(image=orig_image)["image"]
        
        # untransform
        # (image * std) + mean
        # augmented_image = augmented_image * (0.229, 0.224, 0.225) + (0.485, 0.456, 0.406)
        image_list.append(augmented_image)
        label_list.append(label)

    figure, axes = plt.subplots(nrows=1, ncols=count+1, figsize=(22, 4))
    for i in range(count+1):
        axes[i].imshow(image_list[i])
        axes[i].set_title(label_list[i])

# 한국어를 실행을 하지 못함
labels_map = {7 :'몰딩수정', 9:'석고수정', 18:'훼손', 17:'피스', 4:'녹오염', 0:'가구수정', 10:'오염', 5:'들뜸' , 2:'곰팡이',
 14:'창틀,문틀수정', 12:'울음', 11:'오타공', 8:'반점', 6:'면불량', 15:'터짐', 16:'틈새과다' , 1:'걸레받이수정'
 ,13:'이음부불량', 3:'꼬임'}

figure, axes = plt.subplots(nrows=4, ncols=8, figsize=(14, 8))
axes = axes.flatten()

for i in range(32):
  rand_i = np.random.randint(0, 32)
  result = imageset[rand_i]
  image, label = result[0], result[1]
  axes[i].axis('off')
  axes[i].imshow(image.permute(1,2,0))
  axes[i].set_title(labels_map[label])

plt.figure(figsize = (15,12))
for idx, i in enumerate(imageset.label.unique()):
    plt.subplot(4, 7, idx+1)
    
    df = imageset[imageset['label'] == i].reset_index(drop = True)
    # image_path = df.loc[random.randint(0, len(df))-1, 'path']
    image_path = df.loc[random.randint(0, len(df)-1), 'image']
    img = Image.open(image_path)
    img = img.resize((224,224))
    plt.imshow(img)
    plt.axis('off')
    plt.title(i)
plt.tight_layout()
plt.show()

"""# 데이터 적재"""

batch_size = 16
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)
validloader = DataLoader(validset, batch_size=batch_size, shuffle=True)

print(type(trainloader),len(trainloader))
print(type(validloader), len(validloader))

images, labels = next(iter(trainloader))
images.size(), labels.size()

sample_image = images[0]
type(sample_image), sample_image.shape

plt.imshow(sample_image.permute(1, 2, 0))

!nvidia-smi

"""# 모델 컴파인"""

class ResBlock(nn.Module):
  def __init__(self, in_channels, out_channels, shortcut=None, stride=1): # shortcut에 계층을 설정되어 있다면 그 계층을 통과한뒤 Add
    super().__init__()
    
    # 1x1 conv
    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)
    self.batch_norm1 = nn.BatchNorm2d(out_channels)

    # 3x3 conv 
    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1) # stride=2일 경우에는 downsampling
    self.batch_norm2 = nn.BatchNorm2d(out_channels)

    # 1x1 conv
    self.conv3 = nn.Conv2d(out_channels, out_channels*4, kernel_size=1, stride=1, padding=0)
    self.batch_norm3 = nn.BatchNorm2d(out_channels*4)

    self.shortcut = shortcut
    self.stride = stride
    self.relu = nn.ReLU()

  def forward(self, x):
    identity = x.clone()
    x = self.relu(self.batch_norm1(self.conv1(x)))
    x = self.relu(self.batch_norm2(self.conv2(x)))
    x = self.batch_norm3(self.conv3(x))
    
    # shortcut 계층을 바깥에서 설정한것을 적용할 때
    if self.shortcut is not None:
      identity = self.shortcut(identity)

    x += identity  # x = x+identity
    x = self.relu(x)

    return x

class ResNet50(nn.Module):
  def __init__(self):
    super().__init__()
    # conv1
    self.conv1 = nn.Sequential(
                                # BatchNorm 계층은 편향값의 효과를 보완해주므로 관례상 생략략
                                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),
                                nn.BatchNorm2d(num_features=64),
                                nn.ReLU(),                        
                                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
                                ) # [16, 64, 56, 56]
    # conv2_x      
    self.shortcut2 = nn.Sequential(
                                    nn.Conv2d(in_channels=64, out_channels=256, kernel_size=1, stride=1), 
                                    nn.BatchNorm2d(num_features=256)                                  
                                  )              
    self.conv2_x = nn.Sequential(
                                  ResBlock(in_channels=64, out_channels=64, shortcut=self.shortcut2, stride=1),                                 
                                  ResBlock(in_channels=256, out_channels=64, shortcut=None, stride=1),
                                  ResBlock(in_channels=256, out_channels=64, shortcut=None, stride=1)
                                ) # [16, 256, 56, 56]
    # conv3_x
    self.shortcut3 = nn.Sequential(
                                    nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, stride=2), 
                                    nn.BatchNorm2d(num_features=512)                                  
                                  )      
    self.conv3_x = nn.Sequential(
                                  ResBlock(in_channels=256, out_channels=128, shortcut=self.shortcut3, stride=2),
                                  ResBlock(in_channels=512, out_channels=128, shortcut=None, stride=1),
                                  ResBlock(in_channels=512, out_channels=128, shortcut=None, stride=1),
                                  ResBlock(in_channels=512, out_channels=128, shortcut=None, stride=1)

                                ) # [16, 512, 28, 28]   
    # conv4_x
    self.shortcut4 = nn.Sequential(
                                    nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, stride=2), 
                                    nn.BatchNorm2d(num_features=1024)                                  
                                  )      
    self.conv4_x = nn.Sequential(
                                 ResBlock(in_channels=512, out_channels=256, shortcut=self.shortcut4, stride=2),
                                 ResBlock(in_channels=1024, out_channels=256, shortcut=None, stride=1),
                                 ResBlock(in_channels=1024, out_channels=256, shortcut=None, stride=1),
                                 ResBlock(in_channels=1024, out_channels=256, shortcut=None, stride=1),
                                 ResBlock(in_channels=1024, out_channels=256, shortcut=None, stride=1),
                                 ResBlock(in_channels=1024, out_channels=256, shortcut=None, stride=1),                                                                                        
                                ) # [16, 1024, 14, 14] 
    # conv5_x
    self.shortcut5 = nn.Sequential(
                                    nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=1, stride=2), 
                                    nn.BatchNorm2d(num_features=2048)                                  
                                  )    
    self.conv5_x = nn.Sequential(
                                 ResBlock(in_channels=1024, out_channels=512, shortcut=self.shortcut5, stride=2),
                                 ResBlock(in_channels=2048, out_channels=512, shortcut=None, stride=1),
                                 ResBlock(in_channels=2048, out_channels=512, shortcut=None, stride=1),                                                                
                                ) # [16, 2048, 7, 7]  

    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # [16, 2048, 1, 1]                                                                                                                              

    self.classifier = nn.Sequential(
                                nn.Linear(in_features=2048, out_features=2),
                                # nn.BatchNorm1d(num_features=64),
                                # nn.ReLU(),
                                # nn.Linear(in_features=64, out_features=2)
                                )

  def forward(self, x):
    x = self.conv1(x) # [16, 64, 56, 56]
    x = self.conv2_x(x) # [16, 256, 56, 56]
    x = self.conv3_x(x) # [16, 512, 28, 28] 
    x = self.conv4_x(x) # [16, 1024, 14, 14] 
    x = self.conv5_x(x) # [16, 2048, 7, 7] 
    x = self.avg_pool(x) # [16, 2048, 1, 1] 
    
    # reshape할 형상 : (batch_size x 2048)
    # x = x.view(-1, 2048) # option 1 : view
    x = torch.flatten(x, 1) # option 2 : flatten 
    # x = x.reshape(x.shape[0], -1) # option 3 : reshape

    x = self.classifier(x)    
    return x

model = ResNet50()
model.to(device)
model

out = model(images.to(device))
out.shape

for name, parameter in model.named_parameters():
  print(name, parameter.size())

learning_rate = 0.0001
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, verbose=True)

!pip install torchsummary

from torchsummary import summary
summary(model, (3, 224, 224))

"""# 모델 훈련"""

writer = SummaryWriter()

def train_loop(model, trainloader, loss_fn, epochs, optimizer):  
  steps = 0
  steps_per_epoch = len(trainloader) 
  min_loss = 1000000
  max_accuracy = 0
  trigger = 0
  patience = 7 

  for epoch in range(epochs):
    model.train() # 훈련 모드
    train_loss = 0
    for images, labels in trainloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)
      steps += 1
      # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 2. 전방향(forward) 예측
      predict = model(images) # 예측 점수
      loss = loss_fn(predict, labels) # 예측 점수와 정답을 CrossEntropyLoss에 넣어 Loss값 반환

      # 3. 역방향(backward) 오차(Gradient) 전파
      optimizer.zero_grad() # Gradient가 누적되지 않게 하기 위해
      loss.backward() # 모델파리미터들의 Gradient 전파

      # 4. 경사 하강법으로 모델 파라미터 업데이트
      optimizer.step() # W <- W -lr*Gradient

      train_loss += loss.item()
      if (steps % steps_per_epoch) == 0 : 
        model.eval() # 평가 모드 : 평가에서 사용하지 않을 계층(배치 정규화, 드롭아웃)들을 수행하지 않게 하기 위해서
        valid_loss, valid_accuracy = validate(model, validloader, loss_fn)

        # tensorboard 시각화를 위한 로그 이벤트 등록
        writer.add_scalar('Train Loss', train_loss/len(trainloader), epoch+1)
        writer.add_scalar('Valid Loss', valid_loss/len(validloader), epoch+1)
        writer.add_scalars('Train Loss and Valid Loss',
                          {'Train' : train_loss/len(trainloader),
                            'Valid' : valid_loss/len(validloader)}, epoch+1)
        writer.add_scalar('Valid Accuracy', valid_accuracy, epoch+1)
        # -------------------------------------------

        print('Epoch : {}/{}.......'.format(epoch+1, epochs),            
              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)), 
              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)), 
              'Valid Accuracy : {:.3f}'.format(valid_accuracy)            
              )
        
        # Best model 저장    
        # option 1 : valid_loss 모니터링
        # if valid_loss < min_loss: # 바로 이전 epoch의 loss보다 작으면 저장하기
        #   min_loss = valid_loss
        #   best_model_state = deepcopy(model.state_dict())          
        #   torch.save(best_model_state, 'best_checkpoint.pth')     
        
        # option 2 : valid_accuracy 모니터링      
        if valid_accuracy > max_accuracy : # 바로 이전 epoch의 accuracy보다 크면 저장하기
          max_accuracy = valid_accuracy
          best_model_state = deepcopy(model.state_dict())          
          torch.save(best_model_state, 'best_checkpoint.pth')  
        # -------------------------------------------

        # Early Stopping (조기 종료)
        if valid_loss > min_loss: # valid_loss가 min_loss를 갱신하지 못하면
          trigger += 1
          print('trigger : ', trigger)
          if trigger > patience:
            print('Early Stopping !!!')
            print('Training loop is finished !!')
            writer.flush()   
            return
        else:
          trigger = 0
          min_loss = valid_loss
        # -------------------------------------------

        # Learning Rate Scheduler
        scheduler.step(valid_loss)
        # -------------------------------------------
        
  writer.flush()
  return

def validate(model, validloader, loss_fn):
  total = 0   
  correct = 0
  valid_loss = 0
  valid_accuracy = 0

  # 전방향 예측을 구할 때는 gradient가 필요가 없음음
  with torch.no_grad():
    for images, labels in validloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)      
      # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))
      # 0. Data를 GPU로 보내기
      images, labels = images.to(device), labels.to(device)

      # 1. 입력 데이터 준비
      # not Flatten !!
      # images.resize_(images.size()[0], 784)

      # 2. 전방향(Forward) 예측
      logit = model(images) # 예측 점수
      _, preds = torch.max(logit, 1) # 배치에 대한 최종 예측
      # preds = logit.max(dim=1)[1] 
      correct += int((preds == labels).sum()) # 배치 중 맞은 것의 개수가 correct에 누적
      total += labels.shape[0] # 배치 사이즈만큼씩 total에 누적

      loss = loss_fn(logit, labels)
      valid_loss += loss.item() # tensor에서 값을 꺼내와서, 배치의 loss 평균값을 valid_loss에 누적

    valid_accuracy = correct / total
  
  return valid_loss, valid_accuracy

# Commented out IPython magic to ensure Python compatibility.
epochs = 55
# %time train_loop(model, trainloader, loss_fn, epochs, optimizer)
writer.close()

