{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # 파이토치 기본 라이브러리\n\n# torchvision : 데이터셋, 모델 아키텍처, 컴퓨터 비전의 이미지 변환 기능 제공\nfrom torchvision import datasets # torchvision에서 제공하는 데이터셋\nfrom torchvision import transforms # 이미지 변환기능을 제공하는 패키지\n\n# torch.utils.data : 파이토치 데이터 로딩 유틸리티\nfrom torch.utils.data import DataLoader # 모델 훈련에 사용할 수 있는 미니 배치 구성하고\n                                        # 매 epoch마다 데이터를 샘플링, 병렬처리 등의 일을 해주는 함수\n\nfrom torch.utils.data import random_split\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom copy import deepcopy\nfrom sklearn.model_selection import train_test_split\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T05:27:46.109583Z","iopub.execute_input":"2023-04-17T05:27:46.110180Z","iopub.status.idle":"2023-04-17T05:27:46.118294Z","shell.execute_reply.started":"2023-04-17T05:27:46.110137Z","shell.execute_reply":"2023-04-17T05:27:46.117270Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:27:47.238539Z","iopub.execute_input":"2023-04-17T05:27:47.238928Z","iopub.status.idle":"2023-04-17T05:27:48.241148Z","shell.execute_reply.started":"2023-04-17T05:27:47.238895Z","shell.execute_reply":"2023-04-17T05:27:48.239901Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Mon Apr 17 05:27:48 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:27:48.243519Z","iopub.execute_input":"2023-04-17T05:27:48.243995Z","iopub.status.idle":"2023-04-17T05:27:48.312740Z","shell.execute_reply.started":"2023-04-17T05:27:48.243961Z","shell.execute_reply":"2023-04-17T05:27:48.311331Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import glob\nall_img_list = glob.glob('/kaggle/input/doabe/open/train/*/*')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:30.955287Z","iopub.execute_input":"2023-04-17T05:29:30.956229Z","iopub.status.idle":"2023-04-17T05:29:31.276979Z","shell.execute_reply.started":"2023-04-17T05:29:30.956173Z","shell.execute_reply":"2023-04-17T05:29:31.275939Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_img_list = glob.glob('/kaggle/input/doabe/open/test/*')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:31.279033Z","iopub.execute_input":"2023-04-17T05:29:31.279849Z","iopub.status.idle":"2023-04-17T05:29:31.344305Z","shell.execute_reply.started":"2023-04-17T05:29:31.279810Z","shell.execute_reply":"2023-04-17T05:29:31.343312Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"name_list = list(set([i.split('/')[-2] for i in all_img_list]))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:31.346296Z","iopub.execute_input":"2023-04-17T05:29:31.346952Z","iopub.status.idle":"2023-04-17T05:29:31.354534Z","shell.execute_reply.started":"2023-04-17T05:29:31.346913Z","shell.execute_reply":"2023-04-17T05:29:31.353433Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"name_list","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:31.466245Z","iopub.execute_input":"2023-04-17T05:29:31.467233Z","iopub.status.idle":"2023-04-17T05:29:31.474388Z","shell.execute_reply.started":"2023-04-17T05:29:31.467185Z","shell.execute_reply":"2023-04-17T05:29:31.473181Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['오타공',\n '피스',\n '석고수정',\n '가구수정',\n '울음',\n '틈새과다',\n '터짐',\n '몰딩수정',\n '이음부불량',\n '걸레받이수정',\n '오염',\n '면불량',\n '반점',\n '녹오염',\n '창틀,문틀수정',\n '꼬임',\n '들뜸',\n '곰팡이',\n '훼손']"},"metadata":{}}]},{"cell_type":"code","source":"label_dict = {v:i for i, v in enumerate(name_list)}\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:32.346852Z","iopub.execute_input":"2023-04-17T05:29:32.348021Z","iopub.status.idle":"2023-04-17T05:29:32.357069Z","shell.execute_reply.started":"2023-04-17T05:29:32.347970Z","shell.execute_reply":"2023-04-17T05:29:32.355821Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'오타공': 0,\n '피스': 1,\n '석고수정': 2,\n '가구수정': 3,\n '울음': 4,\n '틈새과다': 5,\n '터짐': 6,\n '몰딩수정': 7,\n '이음부불량': 8,\n '걸레받이수정': 9,\n '오염': 10,\n '면불량': 11,\n '반점': 12,\n '녹오염': 13,\n '창틀,문틀수정': 14,\n '꼬임': 15,\n '들뜸': 16,\n '곰팡이': 17,\n '훼손': 18}"},"metadata":{}}]},{"cell_type":"code","source":"train_list, valid_list = train_test_split(all_img_list, test_size= 0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:32.488540Z","iopub.execute_input":"2023-04-17T05:29:32.489263Z","iopub.status.idle":"2023-04-17T05:29:32.503224Z","shell.execute_reply.started":"2023-04-17T05:29:32.489219Z","shell.execute_reply":"2023-04-17T05:29:32.500512Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport glob\nfrom PIL import Image # Image.open(path)\n\nclass Dobaehaja(Dataset):\n    def __init__(self, img_list, transform):\n        self.filepaths = img_list\n        self.transform = transform\n\n\n    def __len__(self):  # len(MyDataset)\n        return len(self.filepaths)\n\n    def __getitem__(self, index): # MyDataset[index]\n\n        # (1) image 준비\n        image_path = self.filepaths\n        img_path = self.filepaths[index]\n        image = Image.open(img_path)\n\n        # https://pytorch.org/vision/stable/transforms.html\n        # 이미지 변환 (파이토치 transforms 에서 제공하는 변환기들은 PIL, tensor 타입을 기대)\n        transformed_image = self.transform(image) # Resize -> To Tensor\n\n        # # (2) label 준비\n        dir_label = img_path.split('/')[-2]\n        name_list = list(set([i.split('/')[-2] for i in self.filepaths]))\n        label_dict = {v:i for i, v in enumerate(name_list)}\n        label = label_dict[dir_label]\n        \n\n        return transformed_image, label","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:32.668917Z","iopub.execute_input":"2023-04-17T05:29:32.669537Z","iopub.status.idle":"2023-04-17T05:29:32.678843Z","shell.execute_reply.started":"2023-04-17T05:29:32.669504Z","shell.execute_reply":"2023-04-17T05:29:32.677678Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Dobaehaja_test(Dataset):\n    def __init__(self, img_list, transform):\n        self.filepaths = img_list\n        self.transform = transform\n\n\n    def __len__(self):  # len(MyDataset)\n        return len(self.filepaths)\n\n    def __getitem__(self, index): # MyDataset[index]\n\n        # (1) image 준비\n        image_path = self.filepaths\n        img_path = self.filepaths[index]\n        image = Image.open(img_path)\n\n        # https://pytorch.org/vision/stable/transforms.html\n        # 이미지 변환 (파이토치 transforms 에서 제공하는 변환기들은 PIL, tensor 타입을 기대)\n        transformed_image = self.transform(image) # Resize -> To Tensor\n\n        # # # (2) label 준비\n        # dir_label = img_path.split('/')[-2]\n        # name_list = list(set([i.split('/')[-2] for i in self.filepaths]))\n        # label_dict = {v:i for i, v in enumerate(name_list)}\n        # label = label_dict[dir_label]\n        \n\n        return transformed_image","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:32.797725Z","iopub.execute_input":"2023-04-17T05:29:32.798485Z","iopub.status.idle":"2023-04-17T05:29:32.805167Z","shell.execute_reply.started":"2023-04-17T05:29:32.798449Z","shell.execute_reply":"2023-04-17T05:29:32.804032Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets # torchvision에서 제공하는 데이터셋\nfrom torchvision import transforms # 이미지 변환기능을 제공하는 패키지\ntransform = transforms.Compose([transforms.Resize([224, 224]), \n                                transforms.RandomHorizontalFlip(p=0.3),\n                                transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:33.024591Z","iopub.execute_input":"2023-04-17T05:29:33.025308Z","iopub.status.idle":"2023-04-17T05:29:33.032851Z","shell.execute_reply.started":"2023-04-17T05:29:33.025268Z","shell.execute_reply":"2023-04-17T05:29:33.031419Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dataset = Dobaehaja(img_list = all_img_list, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:33.394559Z","iopub.execute_input":"2023-04-17T05:29:33.395289Z","iopub.status.idle":"2023-04-17T05:29:33.400300Z","shell.execute_reply.started":"2023-04-17T05:29:33.395248Z","shell.execute_reply":"2023-04-17T05:29:33.398929Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_set = Dobaehaja(img_list = train_list, transform=transform)\nvalid_set = Dobaehaja(img_list = valid_list, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:33.554581Z","iopub.execute_input":"2023-04-17T05:29:33.555521Z","iopub.status.idle":"2023-04-17T05:29:33.561208Z","shell.execute_reply.started":"2023-04-17T05:29:33.555467Z","shell.execute_reply":"2023-04-17T05:29:33.560187Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"test_set = Dobaehaja_test(img_list = test_img_list, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:34.404712Z","iopub.execute_input":"2023-04-17T05:29:34.405446Z","iopub.status.idle":"2023-04-17T05:29:34.410453Z","shell.execute_reply.started":"2023-04-17T05:29:34.405405Z","shell.execute_reply":"2023-04-17T05:29:34.409255Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"len(test_set)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:34.555268Z","iopub.execute_input":"2023-04-17T05:29:34.555990Z","iopub.status.idle":"2023-04-17T05:29:34.562327Z","shell.execute_reply.started":"2023-04-17T05:29:34.555950Z","shell.execute_reply":"2023-04-17T05:29:34.561185Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"792"},"metadata":{}}]},{"cell_type":"code","source":"print(type(train_set), len(train_set))\nprint(type(valid_set), len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:34.696708Z","iopub.execute_input":"2023-04-17T05:29:34.697702Z","iopub.status.idle":"2023-04-17T05:29:34.704791Z","shell.execute_reply.started":"2023-04-17T05:29:34.697661Z","shell.execute_reply":"2023-04-17T05:29:34.703605Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"<class '__main__.Dobaehaja'> 2765\n<class '__main__.Dobaehaja'> 692\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_set[0][0].size(), train_set[0][1])","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:34.841078Z","iopub.execute_input":"2023-04-17T05:29:34.841459Z","iopub.status.idle":"2023-04-17T05:29:34.944516Z","shell.execute_reply.started":"2023-04-17T05:29:34.841426Z","shell.execute_reply":"2023-04-17T05:29:34.943441Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"torch.Size([3, 224, 224]) 9\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. 데이터 적재","metadata":{}},{"cell_type":"code","source":"batch_size = 4 # 16 -> 4\n# dataloader = DataLoader(데이터셋, 배치사이즈, 셔플여부.....)\ntrainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True) # 훈련용 50000개의 데이터를 100개씩 준비\nvalidloader = DataLoader(valid_set, batch_size=batch_size, shuffle=False) # 검증용 10000개의 데이터를 100개씩 준비\ntestloader = DataLoader(test_set, batch_size=batch_size, shuffle=False) # 테스트용 10000개의 데이터를 100개씩 준비","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:35.955969Z","iopub.execute_input":"2023-04-17T05:29:35.956337Z","iopub.status.idle":"2023-04-17T05:29:35.965555Z","shell.execute_reply.started":"2023-04-17T05:29:35.956304Z","shell.execute_reply":"2023-04-17T05:29:35.964524Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(type(trainloader), len(trainloader))\nprint(type(validloader), len(validloader))\nprint(type(testloader), len(testloader))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:36.091941Z","iopub.execute_input":"2023-04-17T05:29:36.092878Z","iopub.status.idle":"2023-04-17T05:29:36.099455Z","shell.execute_reply.started":"2023-04-17T05:29:36.092838Z","shell.execute_reply":"2023-04-17T05:29:36.098304Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"<class 'torch.utils.data.dataloader.DataLoader'> 692\n<class 'torch.utils.data.dataloader.DataLoader'> 173\n<class 'torch.utils.data.dataloader.DataLoader'> 198\n","output_type":"stream"}]},{"cell_type":"code","source":"train_iter = iter(trainloader)\nimages, labels = next(train_iter)\nimages.size(), labels.size()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:29:37.178666Z","iopub.execute_input":"2023-04-17T05:29:37.179296Z","iopub.status.idle":"2023-04-17T05:29:37.301815Z","shell.execute_reply.started":"2023-04-17T05:29:37.179258Z","shell.execute_reply":"2023-04-17T05:29:37.300800Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(torch.Size([4, 3, 224, 224]), torch.Size([4]))"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4. 모델 생성","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:39:32.661109Z","iopub.execute_input":"2023-04-17T02:39:32.661504Z","iopub.status.idle":"2023-04-17T02:39:32.669670Z","shell.execute_reply.started":"2023-04-17T02:39:32.661469Z","shell.execute_reply":"2023-04-17T02:39:32.667659Z"}}},{"cell_type":"code","source":"import torch.nn as nn # 파이토치에서 제공하는 다양한 계층 (Linear Layer, ....)\nimport torch.optim as optim # 옵티마이저 (경사하강법...)\nimport torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:27:30.007968Z","iopub.execute_input":"2023-04-17T05:27:30.008905Z","iopub.status.idle":"2023-04-17T05:27:30.014430Z","shell.execute_reply.started":"2023-04-17T05:27:30.008841Z","shell.execute_reply":"2023-04-17T05:27:30.013181Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\n\n# https://github.com/pytorch/vision/tree/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models\n\nmodel = models.vgg19_bn(weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:21.265196Z","iopub.execute_input":"2023-04-17T05:34:21.265575Z","iopub.status.idle":"2023-04-17T05:34:23.209360Z","shell.execute_reply.started":"2023-04-17T05:34:21.265542Z","shell.execute_reply":"2023-04-17T05:34:23.208161Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for parameter in model.parameters():\n  print(parameter.requires_grad)\n# parameter들의 requires_grad 속성이 True라는 것은 \n# 오차 역전파를 통해 gradient를 전달할 수 있는 상태(즉, 학습이 가능한 상태태)  ","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:28.945365Z","iopub.execute_input":"2023-04-17T05:34:28.946498Z","iopub.status.idle":"2023-04-17T05:34:28.953928Z","shell.execute_reply.started":"2023-04-17T05:34:28.946449Z","shell.execute_reply":"2023-04-17T05:34:28.952814Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"for parameter in model.parameters():\n  parameter.requires_grad = False # 학습이 안되게 고정\n\nfor parameter in model.classifier.parameters():\n  parameter.requires_grad = True # 학습이 가능한 상태","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:29.313061Z","iopub.execute_input":"2023-04-17T05:34:29.313813Z","iopub.status.idle":"2023-04-17T05:34:29.319598Z","shell.execute_reply.started":"2023-04-17T05:34:29.313768Z","shell.execute_reply":"2023-04-17T05:34:29.318468Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model.classifier","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:30.449282Z","iopub.execute_input":"2023-04-17T05:34:30.450361Z","iopub.status.idle":"2023-04-17T05:34:30.457582Z","shell.execute_reply.started":"2023-04-17T05:34:30.450310Z","shell.execute_reply":"2023-04-17T05:34:30.456515Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.classifier[3] = nn.Linear(in_features=4096, out_features=512, bias=True)\nmodel.classifier[6] = nn.Linear(in_features=512, out_features=19, bias=True)\nmodel.classifier","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:30.870803Z","iopub.execute_input":"2023-04-17T05:34:30.871850Z","iopub.status.idle":"2023-04-17T05:34:30.904946Z","shell.execute_reply.started":"2023-04-17T05:34:30.871799Z","shell.execute_reply":"2023-04-17T05:34:30.903797Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=512, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=512, out_features=19, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:33.999618Z","iopub.execute_input":"2023-04-17T05:34:34.000333Z","iopub.status.idle":"2023-04-17T05:34:34.148088Z","shell.execute_reply.started":"2023-04-17T05:34:34.000296Z","shell.execute_reply":"2023-04-17T05:34:34.146929Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=512, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=512, out_features=19, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"out = model(images.to(device))\nout.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:34:35.046316Z","iopub.execute_input":"2023-04-17T05:34:35.046683Z","iopub.status.idle":"2023-04-17T05:34:35.060120Z","shell.execute_reply.started":"2023-04-17T05:34:35.046650Z","shell.execute_reply":"2023-04-17T05:34:35.059008Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 19])"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5. 모델 컴파일","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.0001\n# 손실함수\nloss_fn = nn.CrossEntropyLoss()\n\n# 옵티마이저(최적화함수, 예:경사하강법)\n# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n\n# 규제의 강도 설정 weight_decay\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n\n# Learning Rate Schedule\n# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n\n# 모니터링하고 있는 값(예:valid_loss)의 최소값(min) 또는 최대값(max) patience 기간동안 줄어들지 않을 때(OnPlateau) lr에 factor(0.1)를 곱해주는 전략\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:38:00.370821Z","iopub.execute_input":"2023-04-17T05:38:00.371401Z","iopub.status.idle":"2023-04-17T05:38:00.379880Z","shell.execute_reply.started":"2023-04-17T05:38:00.371358Z","shell.execute_reply":"2023-04-17T05:38:00.378797Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:38:01.763707Z","iopub.execute_input":"2023-04-17T05:38:01.764759Z","iopub.status.idle":"2023-04-17T05:38:11.224672Z","shell.execute_reply.started":"2023-04-17T05:38:01.764695Z","shell.execute_reply":"2023-04-17T05:38:11.223406Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.7/site-packages (1.5.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:38:11.227228Z","iopub.execute_input":"2023-04-17T05:38:11.227523Z","iopub.status.idle":"2023-04-17T05:38:11.234094Z","shell.execute_reply.started":"2023-04-17T05:38:11.227491Z","shell.execute_reply":"2023-04-17T05:38:11.233010Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# summary(모델, (채널, 인풋사이즈))\nsummary(model, (3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:38:11.235220Z","iopub.execute_input":"2023-04-17T05:38:11.235783Z","iopub.status.idle":"2023-04-17T05:38:11.260573Z","shell.execute_reply.started":"2023-04-17T05:38:11.235722Z","shell.execute_reply":"2023-04-17T05:38:11.259469Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n       BatchNorm2d-2         [-1, 64, 224, 224]             128\n              ReLU-3         [-1, 64, 224, 224]               0\n            Conv2d-4         [-1, 64, 224, 224]          36,928\n       BatchNorm2d-5         [-1, 64, 224, 224]             128\n              ReLU-6         [-1, 64, 224, 224]               0\n         MaxPool2d-7         [-1, 64, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]          73,856\n       BatchNorm2d-9        [-1, 128, 112, 112]             256\n             ReLU-10        [-1, 128, 112, 112]               0\n           Conv2d-11        [-1, 128, 112, 112]         147,584\n      BatchNorm2d-12        [-1, 128, 112, 112]             256\n             ReLU-13        [-1, 128, 112, 112]               0\n        MaxPool2d-14          [-1, 128, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         295,168\n      BatchNorm2d-16          [-1, 256, 56, 56]             512\n             ReLU-17          [-1, 256, 56, 56]               0\n           Conv2d-18          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-19          [-1, 256, 56, 56]             512\n             ReLU-20          [-1, 256, 56, 56]               0\n           Conv2d-21          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-22          [-1, 256, 56, 56]             512\n             ReLU-23          [-1, 256, 56, 56]               0\n           Conv2d-24          [-1, 256, 56, 56]         590,080\n      BatchNorm2d-25          [-1, 256, 56, 56]             512\n             ReLU-26          [-1, 256, 56, 56]               0\n        MaxPool2d-27          [-1, 256, 28, 28]               0\n           Conv2d-28          [-1, 512, 28, 28]       1,180,160\n      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n             ReLU-30          [-1, 512, 28, 28]               0\n           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n             ReLU-33          [-1, 512, 28, 28]               0\n           Conv2d-34          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-35          [-1, 512, 28, 28]           1,024\n             ReLU-36          [-1, 512, 28, 28]               0\n           Conv2d-37          [-1, 512, 28, 28]       2,359,808\n      BatchNorm2d-38          [-1, 512, 28, 28]           1,024\n             ReLU-39          [-1, 512, 28, 28]               0\n        MaxPool2d-40          [-1, 512, 14, 14]               0\n           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n             ReLU-43          [-1, 512, 14, 14]               0\n           Conv2d-44          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-45          [-1, 512, 14, 14]           1,024\n             ReLU-46          [-1, 512, 14, 14]               0\n           Conv2d-47          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-48          [-1, 512, 14, 14]           1,024\n             ReLU-49          [-1, 512, 14, 14]               0\n           Conv2d-50          [-1, 512, 14, 14]       2,359,808\n      BatchNorm2d-51          [-1, 512, 14, 14]           1,024\n             ReLU-52          [-1, 512, 14, 14]               0\n        MaxPool2d-53            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-54            [-1, 512, 7, 7]               0\n           Linear-55                 [-1, 4096]     102,764,544\n             ReLU-56                 [-1, 4096]               0\n          Dropout-57                 [-1, 4096]               0\n           Linear-58                  [-1, 512]       2,097,664\n             ReLU-59                  [-1, 512]               0\n          Dropout-60                  [-1, 512]               0\n           Linear-61                   [-1, 19]           9,747\n================================================================\nTotal params: 124,907,347\nTrainable params: 104,871,955\nNon-trainable params: 20,035,392\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 351.91\nParams size (MB): 476.48\nEstimated Total Size (MB): 828.97\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 6. 모델훈련","metadata":{}},{"cell_type":"code","source":"def validate(model, validloader, loss_fn):\n    total = 0   \n    correct = 0\n    valid_loss = 0\n    valid_accuracy = 0\n\n  # 전방향 예측을 구할 때는 gradient가 필요가 없음음\n    with torch.no_grad():\n        for images, labels in validloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)      \n            # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))\n            # 0. Data를 GPU로 보내기\n            images, labels = images.to(device), labels.to(device)\n\n            # 1. 입력 데이터 준비\n            # not Flatten !!\n            # images.resize_(images.size()[0], 784)\n\n            # 2. 전방향(Forward) 예측\n            logit = model(images) # 예측 점수\n            _, preds = torch.max(logit, 1) # 배치에 대한 최종 예측\n            # preds = logit.max(dim=1)[1] \n            correct += int((preds == labels).sum()) # 배치 중 맞은 것의 개수가 correct에 누적\n            total += labels.shape[0] # 배치 사이즈만큼씩 total에 누적\n\n            loss = loss_fn(logit, labels)\n            valid_loss += loss.item() # tensor에서 값을 꺼내와서, 배치의 loss 평균값을 valid_loss에 누적\n\n        valid_accuracy = correct / total\n  \n    return valid_loss, valid_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:38:42.587122Z","iopub.execute_input":"2023-04-17T05:38:42.587496Z","iopub.status.idle":"2023-04-17T05:38:42.596584Z","shell.execute_reply.started":"2023-04-17T05:38:42.587462Z","shell.execute_reply":"2023-04-17T05:38:42.595437Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"writer = SummaryWriter()\n\ndef train_loop(model, trainloader, loss_fn, epochs, optimizer):  \n    steps = 0\n    steps_per_epoch = len(trainloader) \n    min_loss = 1000000\n    max_accuracy = 0\n    trigger = 0\n    patience = 7 \n\n    for epoch in range(epochs):\n        model.train() # 훈련 모드\n        train_loss = 0\n        for images, labels in trainloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)\n            steps += 1\n            # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))\n            # 0. Data를 GPU로 보내기\n            images, labels = images.to(device), labels.to(device)\n\n            # 1. 입력 데이터 준비\n            # not Flatten !!\n            # images.resize_(images.shape[0], 784) \n\n            # 2. 전방향(forward) 예측\n            predict = model(images) # 예측 점수\n            loss = loss_fn(predict, labels) # 예측 점수와 정답을 CrossEntropyLoss에 넣어 Loss값 반환\n\n            # 3. 역방향(backward) 오차(Gradient) 전파\n            optimizer.zero_grad() # Gradient가 누적되지 않게 하기 위해\n            loss.backward() # 모델파리미터들의 Gradient 전파\n\n            # 4. 경사 하강법으로 모델 파라미터 업데이트\n            optimizer.step() # W <- W -lr*Gradient\n\n            train_loss += loss.item()\n            if (steps % steps_per_epoch) == 0 : \n                model.eval() # 평가 모드 : 평가에서 사용하지 않을 계층(배치 정규화, 드롭아웃)들을 수행하지 않게 하기 위해서\n                valid_loss, valid_accuracy = validate(model, validloader, loss_fn)\n\n                # tensorboard 시각화를 위한 로그 이벤트 등록\n                writer.add_scalar('Train Loss', train_loss/len(trainloader), epoch+1)\n                writer.add_scalar('Valid Loss', valid_loss/len(validloader), epoch+1)\n                writer.add_scalars('Train Loss and Valid Loss',\n                                  {'Train' : train_loss/len(trainloader),\n                                    'Valid' : valid_loss/len(validloader)}, epoch+1)\n                writer.add_scalar('Valid Accuracy', valid_accuracy, epoch+1)\n                # -------------------------------------------\n\n                print('Epoch : {}/{}.......'.format(epoch+1, epochs),            \n                      'Train Loss : {:.3f}'.format(train_loss/len(trainloader)), \n                      'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)), \n                      'Valid Accuracy : {:.3f}'.format(valid_accuracy)            \n                      )\n        \n                # Best model 저장    \n                # option 1 : valid_loss 모니터링\n                # if valid_loss < min_loss: # 바로 이전 epoch의 loss보다 작으면 저장하기\n                #   min_loss = valid_loss\n                #   best_model_state = deepcopy(model.state_dict())          \n                #   torch.save(best_model_state, 'best_checkpoint.pth')     \n\n                # option 2 : valid_accuracy 모니터링      \n                if valid_accuracy > max_accuracy : # 바로 이전 epoch의 accuracy보다 크면 저장하기\n                    max_accuracy = valid_accuracy\n                    best_model_state = deepcopy(model.state_dict())          \n                    torch.save(best_model_state, 'best_checkpoint.pth')  \n                # -------------------------------------------\n\n                # Early Stopping (조기 종료)\n                if valid_loss > min_loss: # valid_loss가 min_loss를 갱신하지 못하면\n                    trigger += 1\n                    print('trigger : ', trigger)\n                    if trigger > patience:\n                        print('Early Stopping !!!')\n                        print('Training loop is finished !!')\n                        writer.flush()   \n                        return\n                    else:\n                        trigger = 0\n                        min_loss = valid_loss\n                # -------------------------------------------\n\n                # Learning Rate Scheduler\n                scheduler.step(valid_loss)\n                # -------------------------------------------\n\n    writer.flush()\n    return  ","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:39:40.790304Z","iopub.execute_input":"2023-04-17T05:39:40.790685Z","iopub.status.idle":"2023-04-17T05:39:40.807048Z","shell.execute_reply.started":"2023-04-17T05:39:40.790651Z","shell.execute_reply":"2023-04-17T05:39:40.805977Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"epochs = 55\n%time train_loop(model, trainloader, loss_fn, epochs, optimizer)\nwriter.close()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:39:41.447468Z","iopub.execute_input":"2023-04-17T05:39:41.448583Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch : 1/55....... Train Loss : 1.710 Valid Loss : 1.670 Valid Accuracy : 0.523\nEpoch : 2/55....... Train Loss : 1.290 Valid Loss : 1.747 Valid Accuracy : 0.553\nEpoch : 3/55....... Train Loss : 1.041 Valid Loss : 1.628 Valid Accuracy : 0.618\nEpoch : 4/55....... Train Loss : 0.918 Valid Loss : 1.795 Valid Accuracy : 0.588\nEpoch : 5/55....... Train Loss : 0.795 Valid Loss : 1.764 Valid Accuracy : 0.613\nEpoch : 6/55....... Train Loss : 0.722 Valid Loss : 1.904 Valid Accuracy : 0.614\nEpoch : 7/55....... Train Loss : 0.605 Valid Loss : 1.835 Valid Accuracy : 0.637\nEpoch : 8/55....... Train Loss : 0.577 Valid Loss : 2.008 Valid Accuracy : 0.621\nEpoch 00008: reducing learning rate of group 0 to 1.0000e-05.\nEpoch : 9/55....... Train Loss : 0.396 Valid Loss : 2.017 Valid Accuracy : 0.627\nEpoch : 10/55....... Train Loss : 0.348 Valid Loss : 1.945 Valid Accuracy : 0.645\nEpoch : 11/55....... Train Loss : 0.328 Valid Loss : 2.028 Valid Accuracy : 0.647\nEpoch : 12/55....... Train Loss : 0.298 Valid Loss : 2.223 Valid Accuracy : 0.630\nEpoch : 13/55....... Train Loss : 0.305 Valid Loss : 2.251 Valid Accuracy : 0.649\nEpoch 00013: reducing learning rate of group 0 to 1.0000e-06.\nEpoch : 14/55....... Train Loss : 0.271 Valid Loss : 2.209 Valid Accuracy : 0.640\nEpoch : 15/55....... Train Loss : 0.269 Valid Loss : 2.095 Valid Accuracy : 0.652\nEpoch : 16/55....... Train Loss : 0.274 Valid Loss : 2.018 Valid Accuracy : 0.656\nEpoch : 17/55....... Train Loss : 0.266 Valid Loss : 1.887 Valid Accuracy : 0.656\nEpoch : 18/55....... Train Loss : 0.282 Valid Loss : 2.092 Valid Accuracy : 0.637\nEpoch 00018: reducing learning rate of group 0 to 1.0000e-07.\nEpoch : 19/55....... Train Loss : 0.269 Valid Loss : 2.031 Valid Accuracy : 0.650\nEpoch : 20/55....... Train Loss : 0.277 Valid Loss : 2.305 Valid Accuracy : 0.645\nEpoch : 21/55....... Train Loss : 0.276 Valid Loss : 2.097 Valid Accuracy : 0.636\nEpoch : 22/55....... Train Loss : 0.286 Valid Loss : 2.124 Valid Accuracy : 0.637\nEpoch : 23/55....... Train Loss : 0.278 Valid Loss : 2.166 Valid Accuracy : 0.659\nEpoch 00023: reducing learning rate of group 0 to 1.0000e-08.\nEpoch : 24/55....... Train Loss : 0.264 Valid Loss : 1.936 Valid Accuracy : 0.675\nEpoch : 25/55....... Train Loss : 0.252 Valid Loss : 2.027 Valid Accuracy : 0.668\nEpoch : 26/55....... Train Loss : 0.264 Valid Loss : 2.302 Valid Accuracy : 0.620\nEpoch : 27/55....... Train Loss : 0.272 Valid Loss : 2.023 Valid Accuracy : 0.649\nEpoch : 28/55....... Train Loss : 0.267 Valid Loss : 1.882 Valid Accuracy : 0.656\nEpoch : 29/55....... Train Loss : 0.275 Valid Loss : 2.054 Valid Accuracy : 0.659\nEpoch : 30/55....... Train Loss : 0.268 Valid Loss : 2.149 Valid Accuracy : 0.639\nEpoch : 31/55....... Train Loss : 0.278 Valid Loss : 1.938 Valid Accuracy : 0.666\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 7. 모델 예측","metadata":{}},{"cell_type":"code","source":"test_iter = iter(testloader)\nimages = next(test_iter)\n\n\nimages = images.to(device)\nprint(images.size())\nrnd_idx = 2\nimage = images[rnd_idx:rnd_idx+1]\n# key_pt = key_pts[rnd_idx:rnd_idx+1]\n\nwith torch.no_grad():\n    model.eval() # 배치 정규화가 들어가면서 전방향 연산이 학습시와는 달라지므로 반드시 eval() 넣어야 함\n    logit = model(image)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:56:15.827507Z","iopub.execute_input":"2023-04-17T03:56:15.827887Z","iopub.status.idle":"2023-04-17T03:56:15.899258Z","shell.execute_reply.started":"2023-04-17T03:56:15.827848Z","shell.execute_reply":"2023-04-17T03:56:15.898070Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"images[rnd_idx].shape","metadata":{"execution":{"iopub.status.busy":"2023-04-17T03:56:16.205198Z","iopub.execute_input":"2023-04-17T03:56:16.206123Z","iopub.status.idle":"2023-04-17T03:56:16.213539Z","shell.execute_reply.started":"2023-04-17T03:56:16.206072Z","shell.execute_reply":"2023-04-17T03:56:16.212417Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    logit = model(images[rnd_idx].unsqueeze(0)) # model.forward()에서는 배치가 적용된 4차원 입력 기대\n\npred = logit.max(dim=1)[1]\nprint(pred == labels[rnd_idx])","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:21:59.960143Z","iopub.execute_input":"2023-04-17T05:21:59.961397Z","iopub.status.idle":"2023-04-17T05:22:00.053771Z","shell.execute_reply.started":"2023-04-17T05:21:59.961335Z","shell.execute_reply":"2023-04-17T05:22:00.051961Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3214202242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model.forward()에서는 배치가 적용된 4차원 입력 기대\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}