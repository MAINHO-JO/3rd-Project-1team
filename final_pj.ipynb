{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xMeDfHabvtDI"
      },
      "outputs": [],
      "source": [
        "import torch # 파이토치 기본 라이브러리\n",
        "\n",
        "# torchvision : 데이터셋, 모델 아키텍처, 컴퓨터 비전의 이미지 변환 기능 제공\n",
        "from torchvision import datasets # torchvision에서 제공하는 데이터셋\n",
        "from torchvision import transforms # 이미지 변환기능을 제공하는 패키지\n",
        "\n",
        "# torch.utils.data : 파이토치 데이터 로딩 유틸리티\n",
        "from torch.utils.data import DataLoader # 모델 훈련에 사용할 수 있는 미니 배치 구성하고\n",
        "                                        # 매 epoch마다 데이터를 샘플링, 병렬처리 등의 일을 해주는 함수\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkKvgX1Jvw1m",
        "outputId": "c07771a0-9ffb-4fae-efbf-acf7294df8fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WeFtax7v41u",
        "outputId": "bf567f88-ba1c-43c8-dc0c-2a47cd2e5cd8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjXd2dkrv6S-",
        "outputId": "2dc695ab-a778-40b0-a45e-f363290a7906"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cnU33e0Av-L3",
        "outputId": "736c0acb-76e0-4785-f4fa-2fc710b0a890"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/pj3/open.zip' './'\n",
        "!unzip -q open.zip -d open/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VCprXAxv-pu",
        "outputId": "1d98195d-83df-4e06-ca8c-228685bd9c02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "8PTLtsizwAye"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "j5BWNDQpwES-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from PIL import Image # Image.open(path)\n",
        "test_dict={'몰딩수정':0, '석고수정':1, '훼손':2, '피스':3, '녹오염':4, '가구수정':5, '오염':6, '들뜸':7, '곰팡이':8,\n",
        "       '창틀,문틀수정':9, '울음':10, '오타공':11, '반점':12, '면불량':13, '터짐':14, '틈새과다':15, '걸레받이수정':16,\n",
        "       '이음부불량':17, '꼬임':18}\n",
        "class remodelDataset(Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.filepaths = glob.glob(root + '*/*.png')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):  # len(MyDataset)\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, index): # MyDataset[index]\n",
        "\n",
        "        # (1) image 준비\n",
        "        image_filepath = self.filepaths[index]\n",
        "        image = Image.open(image_filepath)         \n",
        "\n",
        "        \n",
        "        transformed_image = self.transform(image) # Resize -> To Tensor\n",
        "\n",
        "        # (2) label 준비\n",
        "        dir_label = image_filepath.split('/')[-2]\n",
        "        label_=test_dict[dir_label]\n",
        "        return transformed_image ,label_\n",
        "    "
      ],
      "metadata": {
        "id": "X5An0znrwGPO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = remodelDataset(root ='/content/open/train/', transform=transform)"
      ],
      "metadata": {
        "id": "9JU-ZtUQwOaW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_img_list = glob.glob('./open/train/*/*.png')"
      ],
      "metadata": {
        "id": "i3ICTD0OwQ-G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = all_img_list\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])"
      ],
      "metadata": {
        "id": "zxirFaJUwSxu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "vyLBISFdwUzu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df['label_num'] = le.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "QiOBcRNqwWTO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kG7nejRiwX1d",
        "outputId": "df09b093-0512-4e6a-9ff3-ea3a5798c3b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      img_path label  label_num\n",
              "0       ./open/train/녹오염/1.png   녹오염          4\n",
              "1      ./open/train/녹오염/11.png   녹오염          4\n",
              "2       ./open/train/녹오염/5.png   녹오염          4\n",
              "3       ./open/train/녹오염/6.png   녹오염          4\n",
              "4      ./open/train/녹오염/12.png   녹오염          4\n",
              "...                        ...   ...        ...\n",
              "3452   ./open/train/훼손/413.png    훼손         18\n",
              "3453   ./open/train/훼손/113.png    훼손         18\n",
              "3454   ./open/train/훼손/954.png    훼손         18\n",
              "3455  ./open/train/훼손/1320.png    훼손         18\n",
              "3456  ./open/train/훼손/1266.png    훼손         18\n",
              "\n",
              "[3457 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-639aadc4-0436-4765-9110-98f6ce959213\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./open/train/녹오염/1.png</td>\n",
              "      <td>녹오염</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./open/train/녹오염/11.png</td>\n",
              "      <td>녹오염</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./open/train/녹오염/5.png</td>\n",
              "      <td>녹오염</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./open/train/녹오염/6.png</td>\n",
              "      <td>녹오염</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./open/train/녹오염/12.png</td>\n",
              "      <td>녹오염</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>./open/train/훼손/413.png</td>\n",
              "      <td>훼손</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>./open/train/훼손/113.png</td>\n",
              "      <td>훼손</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3454</th>\n",
              "      <td>./open/train/훼손/954.png</td>\n",
              "      <td>훼손</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3455</th>\n",
              "      <td>./open/train/훼손/1320.png</td>\n",
              "      <td>훼손</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>./open/train/훼손/1266.png</td>\n",
              "      <td>훼손</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3457 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-639aadc4-0436-4765-9110-98f6ce959213')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-639aadc4-0436-4765-9110-98f6ce959213 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-639aadc4-0436-4765-9110-98f6ce959213');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_indices, valid_indices = train_test_split(\n",
        "                            range(len(df)), # X의 index\n",
        "                             # y\n",
        "                            stratify=df.label_num, # target의 비율이 train과 valid에 그대로 반영되게\n",
        "                            test_size= 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NjrWtL5QwYop"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "train_set = Subset(trainset, train_indices)\n",
        "valid_set = Subset(trainset, valid_indices)"
      ],
      "metadata": {
        "id": "vCBR6sUowbnf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # 100 -> 16\n",
        "# dataloader = DataLoader(데이터셋, 배치사이즈, 셔플여부.....)\n",
        "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True) # 훈련용 50000개의 데이터를 100개씩 준비\n",
        "validloader = DataLoader(valid_set, batch_size=batch_size, shuffle=False) # 검증용 10000개의 데이터를 100개씩 준비"
      ],
      "metadata": {
        "id": "DZP7_cxNwgdm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(trainloader), len(trainloader))\n",
        "print(type(validloader), len(validloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29xCP53whPm",
        "outputId": "5f3dec58-dee2-40d8-f2d9-df4a72abef22"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'> 173\n",
            "<class 'torch.utils.data.dataloader.DataLoader'> 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # 파이토치에서 제공하는 다양한 계층 (Linear Layer, ....)\n",
        "import torch.optim as optim # 옵티마이저 (경사하강법...)\n",
        "import torch.nn.functional as F "
      ],
      "metadata": {
        "id": "j7tcwrZ8whM-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(trainloader)\n",
        "images, labels = next(train_iter)\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snj7PWFdwhKR",
        "outputId": "21a41d45-4b59-4401-bc48-9abbfab53fa1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBT4uPliwhHe",
        "outputId": "e9d9c938-4ae3-426e-ab27-6a510e1a0307"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6,  2, 13,  0,  2,  2, 13,  6,  2,  8, 16,  6, 16,  2,  2, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_block5 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=256),\n",
        "                                      nn.Dropout(0.1), \n",
        "                                      nn.ReLU(),   \n",
        "                                      nn.MaxPool2d(kernel_size=3, stride=2)                                   \n",
        "                                     )\n",
        "conv_block5_out = conv_block5(images)                                     \n",
        "conv_block5_out.shape"
      ],
      "metadata": {
        "id": "-jxAV4NRx6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ofs336ibx6G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=96),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "                                     ) # [16, 96, 111, 111]\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=256),                                      \n",
        "                                      nn.ReLU(),\n",
        "                                      nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "                                     ) # [16, 256, 111, 111]\n",
        "\n",
        "    self.conv_block3 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=384), \n",
        "                                      nn.Dropout(0.1),                                    \n",
        "                                      nn.ReLU(),                                      \n",
        "                                     ) # [16, 384, 224, 224]     \n",
        "\n",
        "    self.conv_block4 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=384),  \n",
        "                                      nn.Dropout(0.3),                                    \n",
        "                                      nn.ReLU(),                                      \n",
        "                                     ) # [16, 384, 224, 224]   \n",
        "\n",
        "    self.conv_block5 = nn.Sequential(\n",
        "                                      nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "                                      nn.BatchNorm2d(num_features=256),\n",
        "                                      nn.Dropout(0.1), \n",
        "                                      nn.ReLU(),   \n",
        "                                      nn.MaxPool2d(kernel_size=3, stride=2)                                   \n",
        "                                     ) # [16, 256, 3, 3]                                                                                                       \n",
        "\n",
        "    self.linear1 = nn.Linear(in_features=256*3*3, out_features=512)\n",
        "    self.batch_norm = nn.BatchNorm1d(num_features=512)\n",
        "    self.linear2 = nn.Linear(in_features=512, out_features=19)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x) \n",
        "    x = self.conv_block2(x) \n",
        "    x = self.conv_block3(x) \n",
        "    x = self.conv_block4(x) \n",
        "    x = self.conv_block5(x) \n",
        "    \n",
        "    # reshape할 형상 : (batch_size x 256*3*3)\n",
        "    # x = x.view(-1, 256*3*3) # option 1 : view\n",
        "    x = torch.flatten(x, 1) # option 2 : flatten \n",
        "    # x = x.reshape(x.shape[0], -1) # option 3 : reshape\n",
        "    x = F.dropout(x, 0.3)\n",
        "    x = self.linear1(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = F.dropout(x, 0.1)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VwsexXrLwpBN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet()\n",
        "model.to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSeI4VoFwo-x",
        "outputId": "60d1f419-8a7c-4892-ad7b-36c227c5a211"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (conv_block1): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block2): Sequential(\n",
              "    (0): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block3): Sequential(\n",
              "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (conv_block4): Sequential(\n",
              "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (conv_block5): Sequential(\n",
              "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (linear1): Linear(in_features=2304, out_features=512, bias=True)\n",
              "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "# 손실함수\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저(최적화함수, 예:경사하강법)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 규제의 강도 설정 weight_decay\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "# Learning Rate Schedule\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
        "\n",
        "# 모니터링하고 있는 값(예:valid_loss)의 최소값(min) 또는 최대값(max) patience 기간동안 줄어들지 않을 때(OnPlateau) lr에 factor(0.1)를 곱해주는 전략\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, verbose=True)"
      ],
      "metadata": {
        "id": "S553McL3wo8t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "rRoCM_nFwo6W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jDGZm3bwo1a",
        "outputId": "0f4a45df-945e-46a1-e841-8cc1f06e84de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 32, 32]           2,688\n",
            "       BatchNorm2d-2           [-1, 96, 32, 32]             192\n",
            "              ReLU-3           [-1, 96, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 96, 15, 15]               0\n",
            "            Conv2d-5          [-1, 256, 15, 15]         221,440\n",
            "       BatchNorm2d-6          [-1, 256, 15, 15]             512\n",
            "              ReLU-7          [-1, 256, 15, 15]               0\n",
            "         MaxPool2d-8            [-1, 256, 7, 7]               0\n",
            "            Conv2d-9            [-1, 384, 7, 7]         885,120\n",
            "      BatchNorm2d-10            [-1, 384, 7, 7]             768\n",
            "          Dropout-11            [-1, 384, 7, 7]               0\n",
            "             ReLU-12            [-1, 384, 7, 7]               0\n",
            "           Conv2d-13            [-1, 384, 7, 7]       1,327,488\n",
            "      BatchNorm2d-14            [-1, 384, 7, 7]             768\n",
            "          Dropout-15            [-1, 384, 7, 7]               0\n",
            "             ReLU-16            [-1, 384, 7, 7]               0\n",
            "           Conv2d-17            [-1, 256, 7, 7]         884,992\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "          Dropout-19            [-1, 256, 7, 7]               0\n",
            "             ReLU-20            [-1, 256, 7, 7]               0\n",
            "        MaxPool2d-21            [-1, 256, 3, 3]               0\n",
            "           Linear-22                  [-1, 512]       1,180,160\n",
            "      BatchNorm1d-23                  [-1, 512]           1,024\n",
            "           Linear-24                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 4,510,794\n",
            "Trainable params: 4,510,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.39\n",
            "Params size (MB): 17.21\n",
            "Estimated Total Size (MB): 22.60\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, validloader, loss_fn):\n",
        "  total = 0   \n",
        "  correct = 0\n",
        "  valid_loss = 0\n",
        "  valid_accuracy = 0\n",
        "\n",
        "  # 전방향 예측을 구할 때는 gradient가 필요가 없음음\n",
        "  with torch.no_grad():\n",
        "    for images, labels in validloader: # 이터레이터로부터 next()가 호출되며 미니배치 100개씩을 반환(images, labels)      \n",
        "      # images, labels : (torch.Size([16, 3, 32, 32]), torch.Size([16]))\n",
        "      # 0. Data를 GPU로 보내기\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      # 1. 입력 데이터 준비\n",
        "      # not Flatten !!\n",
        "      # images.resize_(images.size()[0], 784)\n",
        "\n",
        "      # 2. 전방향(Forward) 예측\n",
        "      logit = model(images) # 예측 점수\n",
        "      _, preds = torch.max(logit, 1) # 배치에 대한 최종 예측\n",
        "      # preds = logit.max(dim=1)[1] \n",
        "      correct += int((preds == labels).sum()) # 배치 중 맞은 것의 개수가 correct에 누적\n",
        "      total += labels.shape[0] # 배치 사이즈만큼씩 total에 누적\n",
        "\n",
        "      loss = loss_fn(logit, labels)\n",
        "      valid_loss += loss.item() # tensor에서 값을 꺼내와서, 배치의 loss 평균값을 valid_loss에 누적\n",
        "\n",
        "    valid_accuracy = correct / total\n",
        "  \n",
        "  return valid_loss, valid_accuracy"
      ],
      "metadata": {
        "id": "EVOD45Z4woyu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter()\n",
        "\n",
        "def train_loop(model, trainloader, loss_fn, epochs, optimizer):  \n",
        "  steps = 0\n",
        "  steps_per_epoch = len(trainloader) \n",
        "  min_loss = 1000000\n",
        "  max_accuracy = 0\n",
        "  trigger = 0\n",
        "  patience = 7 \n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train() # 훈련 모드\n",
        "    train_loss = 0\n",
        "    for images, labels in trainloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)\n",
        "      steps += 1\n",
        "      # images, labels : (torch.Size([16, 3, 32, 32]), torch.Size([16]))\n",
        "      # 0. Data를 GPU로 보내기\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      # 1. 입력 데이터 준비\n",
        "      # not Flatten !!\n",
        "      # images.resize_(images.shape[0], 784) \n",
        "\n",
        "      # 2. 전방향(forward) 예측\n",
        "      predict = model(images) # 예측 점수\n",
        "      loss = loss_fn(predict, labels) # 예측 점수와 정답을 CrossEntropyLoss에 넣어 Loss값 반환\n",
        "\n",
        "      # 3. 역방향(backward) 오차(Gradient) 전파\n",
        "      optimizer.zero_grad() # Gradient가 누적되지 않게 하기 위해\n",
        "      loss.backward() # 모델파리미터들의 Gradient 전파\n",
        "\n",
        "      # 4. 경사 하강법으로 모델 파라미터 업데이트\n",
        "      optimizer.step() # W <- W -lr*Gradient\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      if (steps % steps_per_epoch) == 0 : \n",
        "        model.eval() # 평가 모드 : 평가에서 사용하지 않을 계층(배치 정규화, 드롭아웃)들을 수행하지 않게 하기 위해서\n",
        "        valid_loss, valid_accuracy = validate(model, validloader, loss_fn)\n",
        "\n",
        "        # tensorboard 시각화를 위한 로그 이벤트 등록\n",
        "        writer.add_scalar('Train Loss', train_loss/len(trainloader), epoch+1)\n",
        "        writer.add_scalar('Valid Loss', valid_loss/len(validloader), epoch+1)\n",
        "        writer.add_scalars('Train Loss and Valid Loss',\n",
        "                          {'Train' : train_loss/len(trainloader),\n",
        "                            'Valid' : valid_loss/len(validloader)}, epoch+1)\n",
        "        writer.add_scalar('Valid Accuracy', valid_accuracy, epoch+1)\n",
        "        # -------------------------------------------\n",
        "\n",
        "        print('Epoch : {}/{}.......'.format(epoch+1, epochs),            \n",
        "              'Train Loss : {:.3f}'.format(train_loss/len(trainloader)), \n",
        "              'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)), \n",
        "              'Valid Accuracy : {:.3f}'.format(valid_accuracy)            \n",
        "              )\n",
        "        \n",
        "        # Best model 저장    \n",
        "        # option 1 : valid_loss 모니터링\n",
        "        # if valid_loss < min_loss: # 바로 이전 epoch의 loss보다 작으면 저장하기\n",
        "        #   min_loss = valid_loss\n",
        "        #   best_model_state = deepcopy(model.state_dict())          \n",
        "        #   torch.save(best_model_state, 'best_checkpoint.pth')     \n",
        "        \n",
        "        # option 2 : valid_accuracy 모니터링      \n",
        "        if valid_accuracy > max_accuracy : # 바로 이전 epoch의 accuracy보다 크면 저장하기\n",
        "          max_accuracy = valid_accuracy\n",
        "          best_model_state = deepcopy(model.state_dict())          \n",
        "          torch.save(best_model_state, 'best_checkpoint.pth')  \n",
        "        # -------------------------------------------\n",
        "\n",
        "        # Early Stopping (조기 종료)\n",
        "        if valid_loss > min_loss: # valid_loss가 min_loss를 갱신하지 못하면\n",
        "          trigger += 1\n",
        "          print('trigger : ', trigger)\n",
        "          if trigger > patience:\n",
        "            print('Early Stopping !!!')\n",
        "            print('Training loop is finished !!')\n",
        "            writer.flush()   \n",
        "            return\n",
        "        else:\n",
        "          trigger = 0\n",
        "          min_loss = valid_loss\n",
        "        # -------------------------------------------\n",
        "\n",
        "        # Learning Rate Scheduler\n",
        "        scheduler.step(valid_loss)\n",
        "        # -------------------------------------------\n",
        "        \n",
        "  writer.flush()\n",
        "  return  "
      ],
      "metadata": {
        "id": "E2gearXNwhFR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 55\n",
        "%time train_loop(model, trainloader, loss_fn, epochs, optimizer)\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "xuajg76sxFM_",
        "outputId": "0010a622-9119-47a6-b238-805c3428e12e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-6bf0c29d225b>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, trainloader, loss_fn, epochs, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;31m# 2. 전방향(forward) 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 예측 점수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 예측 점수와 정답을 CrossEntropyLoss에 넣어 Loss값 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-35c32e48a493>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# x = x.reshape(x.shape[0], -1) # option 3 : reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x186624 and 2304x512)"
          ]
        }
      ]
    }
  ]
}